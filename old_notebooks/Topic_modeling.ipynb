{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from itertools import *\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import unidecode\n",
    "from sklearn.decomposition import NMF\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.en import sentiment, polarity, subjectivity\n",
    "def sentiment(text):\n",
    "    return polarity(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text= text.replace('mrs. ','')\n",
    "    text= text.replace('mr. ','')\n",
    "    text= text.replace('ms. ','')\n",
    "    text= text.replace('dr. ','')\n",
    "    text= text.replace('sen. ','')\n",
    "    text= text.replace('Mrs. ','')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_datetime(x):\n",
    "    return datetime.datetime.fromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentiment_new(text):\n",
    "    def Sentences(paragraph):\n",
    "        sentenceEnders = re.compile('[.!?]')\n",
    "        sentenceList = sentenceEnders.split(paragraph)\n",
    "        return sentenceList\n",
    "    \n",
    "    def to_filter(text):\n",
    "        terms = ['Hilary', 'Clinton', 'Rodham', 'Mrs.Clinton']\n",
    "        if any(word in text for word in terms):\n",
    "            return text\n",
    "        else:\n",
    "            return None \n",
    "    \n",
    "    target= []  \n",
    "    for i in Sentences(text):\n",
    "        if to_filter(i) == None:\n",
    "            pass\n",
    "        else:\n",
    "            target.append(i)\n",
    "            \n",
    "    s_max = 0\n",
    "    comment_score = 0\n",
    "    \n",
    "    for i in target:\n",
    "        content = unidecode.unidecode(i).replace(\"\\n\",\" \").replace(\"\\'s\",\"\").replace(\"\\'t\",\"\")\n",
    "        if abs(sentiment(content)) > abs(s_max):\n",
    "            comment_score = sentiment(i)\n",
    "            s_max = sentiment(content)\n",
    "    \n",
    "    return comment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:26: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n",
      "/Users/datascientist/anaconda/lib/python2.7/site-packages/Pattern-2.6-py2.7.egg/pattern/text/__init__.py:2228: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if w in map(lambda e: e.lower(), e):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24983\n",
      "980\n",
      "1474\n"
     ]
    }
   ],
   "source": [
    "hilary = pd.read_csv('data/hilary_scores.csv')\n",
    "hilary['Sentiment'] = hilary.apply(lambda row: sentiment_new(row['Comment']), axis = 1)\n",
    "neg = hilary[hilary['Sentiment'] < -0.1]\n",
    "print len(neg)\n",
    "pos = hilary[hilary['Sentiment'] > 0.2]\n",
    "print len(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2454"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg) + len(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Topic #1:\n",
      "president hillary woman america rodham\n",
      "Topic #2:\n",
      "email server private state information\n",
      "Topic #3:\n",
      "times coverage story ny page\n",
      "Topic #4:\n",
      "biden joe run clinton president\n",
      "Topic #5:\n",
      "sanders bernie hillary support clinton\n",
      "Topic #6:\n",
      "trump republican bush gop donald\n",
      "Topic #7:\n",
      "win election democratic nomination party\n",
      "Topic #8:\n",
      "nyt news sources story anonymous\n",
      "Topic #9:\n",
      "hilary bernie win like joe\n",
      "Topic #10:\n",
      "change mrs people black clinton\n",
      "##################################################\n",
      "Topic #1:\n",
      "biden joe run president obama\n",
      "Topic #2:\n",
      "times story news coverage clinton\n",
      "Topic #3:\n",
      "black matter lives blm apology\n",
      "Topic #4:\n",
      "sanders bernie support hillary democrat\n",
      "Topic #5:\n",
      "clintons bushes sick tired barry\n",
      "Topic #6:\n",
      "republican party vote democratic candidate\n",
      "Topic #7:\n",
      "trump bush jeb donald hillary\n",
      "Topic #8:\n",
      "classified server email information state\n",
      "Topic #9:\n",
      "people clinton know like want\n",
      "Topic #10:\n",
      "crime violent law laws blow\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "list_ = [pos, neg]\n",
    "examples = []\n",
    "num_per_topics = []\n",
    "topics = []\n",
    "\n",
    "for i in list_: \n",
    "    V = vectorizer.fit_transform(i['Comment'].values).toarray()\n",
    "    features = vectorizer.get_feature_names()\n",
    "    nmf = NMF(n_components=10).fit(V)\n",
    "    matrix = nmf.transform(V)\n",
    "    index = matrix.argmax(axis=0)\n",
    "    i = i.reset_index()\n",
    "    examples.append(i.ix[index]['Comment'].values)\n",
    "    matrix = nmf.transform(V)\n",
    "    np.sort(matrix, axis =1)\n",
    "    values = []\n",
    "    keyterms = []\n",
    "\n",
    "    for i in range(10):\n",
    "        values.append(len(matrix[:,i][matrix[:,i] > 0.05]))\n",
    "\n",
    "    print(\"##################################################\")\n",
    "    for topic_idx, topic in enumerate(nmf.components_, 1):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([features[i]\n",
    "                for i in topic.argsort()[:-5 -1:-1]]))\n",
    "\n",
    "        keyterms.append(\" \".join([features[i]\n",
    "                for i in topic.argsort()[:-5 -1:-1]]))\n",
    "\n",
    "    num_per_topics.append(values)\n",
    "    topics.append(keyterms)\n",
    "\n",
    "pos_examples = examples[0]\n",
    "neg_examples = examples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos1= list(izip(topics[0], pos_examples))\n",
    "data_pos = pd.DataFrame(list(izip(pos1, num_per_topics[0])))\n",
    "data_pos[['pos_keys', 'pos_ex']] = data_pos[0].apply(pd.Series)\n",
    "data_pos.rename(columns={1:'pos_num'}, inplace=True)\n",
    "data_pos.drop(0, axis = 1, inplace=True)\n",
    "\n",
    "neg1= list(izip(topics[1], neg_examples))\n",
    "data_neg = pd.DataFrame(list(izip(neg1, num_per_topics[1])))\n",
    "data_neg[['neg_keys', 'neg_ex']] = data_neg[0].apply(pd.Series)\n",
    "data_neg.rename(columns={1:'neg_num'}, inplace=True)\n",
    "data_neg.drop(0, axis = 1, inplace=True)\n",
    "\n",
    "comments = pd.concat([data_pos, data_neg], axis = 1)\n",
    "comments['pos_keys'] = comments['pos_keys'].apply(lambda x : clean_text(x))\n",
    "comments['neg_keys'] = comments['neg_keys'].apply(lambda x : clean_text(x))\n",
    "comments.to_csv('data/hilary_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_new(text):\n",
    "    def Sentences(paragraph):\n",
    "        sentenceEnders = re.compile('[.!?]')\n",
    "        sentenceList = sentenceEnders.split(paragraph)\n",
    "        return sentenceList\n",
    "    \n",
    "    def to_filter(text):\n",
    "        terms = ['Sanders', 'Bernie', 'Mr.Sanders']\n",
    "        if any(word in text for word in terms):\n",
    "            return text\n",
    "        else:\n",
    "            return None \n",
    "    \n",
    "    target= [] \n",
    "    #sent = Sentences(text)   \n",
    "    for i in Sentences(text):\n",
    "        if to_filter(i) == None:\n",
    "            pass\n",
    "        else:\n",
    "            target.append(i)\n",
    "            \n",
    "    s_max = 0\n",
    "    comment_score = 0\n",
    "    \n",
    "    for i in target:\n",
    "        content = unidecode.unidecode(i).replace(\"\\n\",\" \").replace(\"\\'s\",\"\").replace(\"\\'t\",\"\")\n",
    "        if abs(sentiment(content)) > abs(s_max):\n",
    "            comment_score = sentiment(i)\n",
    "            s_max = sentiment(content)\n",
    "    \n",
    "    return comment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n",
      "1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:26: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not operate 1156 with block values unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-009d5732c2d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msanders_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msanders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanders_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanders_pos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msanders_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/datascientist/anaconda/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m    919\u001b[0m                                  (other.shape, ))\n\u001b[1;32m    920\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_const\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/datascientist/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_combine_const\u001b[0;34m(self, other, func, raise_on_error)\u001b[0m\n\u001b[1;32m   3226\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3228\u001b[0;31m         \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3229\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/datascientist/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   2478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/datascientist/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, **kwargs)\u001b[0m\n\u001b[1;32m   2457\u001b[0m                                                  copy=align_copy)\n\u001b[1;32m   2458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2459\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2461\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/datascientist/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, func, other, raise_on_error, try_cast)\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;31m# technically a broadcast error in numpy can 'work' by returning a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/datascientist/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mhandle_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                 raise TypeError('Could not operate %s with block values %s'\n\u001b[0;32m--> 963\u001b[0;31m                                 % (repr(other), str(detail)))\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0;31m# return the values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not operate 1156 with block values unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "sanders = pd.read_csv('data/sanders_scores.csv')\n",
    "sanders[pd.isnull(sanders['Comment'])] = \"\"\n",
    "\n",
    "sanders['Sentiment'] = sanders.apply(lambda row: sentiment_new(row['Comment']), axis = 1)\n",
    "\n",
    "sanders_neg = sanders[sanders['Sentiment'] < -0.1]\n",
    "print len(sanders_neg)\n",
    "sanders_pos = sanders[sanders['Sentiment'] > 0.1]\n",
    "print len(sanders_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1395\n"
     ]
    }
   ],
   "source": [
    "print len(sanders_pos) + len(sanders_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Topic #1:\n",
      "vote primary ll election general bernie hope republican democratic voting\n",
      "Topic #2:\n",
      "love bernie sanders fight stands good believes agree 59 leader\n",
      "Topic #3:\n",
      "people tax class country american pay middle money social way\n",
      "Topic #4:\n",
      "win good lose want bernie luck don nomination sale sanders\n",
      "Topic #5:\n",
      "senator sanders mr good wish agree times america elected speak\n",
      "Topic #6:\n",
      "hillary clinton left sanders support bush obama republicans warren far\n",
      "Topic #7:\n",
      "candidate democratic candidates issues party voters republican campaign sanders media\n",
      "Topic #8:\n",
      "right need left america bernie people wing person puts sanders\n",
      "Topic #9:\n",
      "like bernie need fresh vermont stand air breath chance know\n",
      "Topic #10:\n",
      "president sanders running bernie run ticket person democratic socialist make\n",
      "##################################################\n",
      "Topic #1:\n",
      "hillary clinton sanders issues just doesn ll good look make\n",
      "Topic #2:\n",
      "truth say guts reality senators sanders power speak bernie honesty\n",
      "Topic #3:\n",
      "vote chance getting bernie nomination little know ll got hands\n",
      "Topic #4:\n",
      "bernie great small just thing politician candidate work political gail\n",
      "Topic #5:\n",
      "senator acknowledged sanders candidate courage long profile issue effort compromise\n",
      "Topic #6:\n",
      "president let badly universe bernie sanders different obama understands need\n",
      "Topic #7:\n",
      "money tax sanders country education sen corporate need jobs ordinary\n",
      "Topic #8:\n",
      "people american class tpp middle stand energy bernie america needs\n",
      "Topic #9:\n",
      "party democratic republican warren left don democrats candidate elizabeth sanders\n",
      "Topic #10:\n",
      "mr media sanders socialist times voters candidacy fox voice coverage\n"
     ]
    }
   ],
   "source": [
    "list_ = [sanders_pos, sanders_neg]\n",
    "sanders_examples = []\n",
    "num_per_topics = []\n",
    "\n",
    "for i in list_: \n",
    "    V = vectorizer.fit_transform(i['Comment'].values).toarray()\n",
    "    features = vectorizer.get_feature_names()\n",
    "    nmf = NMF(n_components=10).fit(V)\n",
    "\n",
    "    #print nmf.transform(V).shape\n",
    "    matrix = nmf.transform(V)\n",
    "    index = matrix.argmax(axis=0)\n",
    "    i = i.reset_index()\n",
    "    sanders_examples.append(i.ix[index]['Comment'].values)\n",
    "    matrix = nmf.transform(V)\n",
    "    np.sort(matrix, axis =1)\n",
    "    values = []\n",
    "    for i in range(10):\n",
    "        values.append(len(matrix[:,i][matrix[:,i] > 0.05]))\n",
    "    \n",
    "    print(\"##################################################\")\n",
    "    for topic_idx, topic in enumerate(nmf.components_, 1):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([features[i]\n",
    "                for i in topic.argsort()[:-10 -1:-1]]))\n",
    "        numbers.append(np.count_nonzero(topic))\n",
    "        \n",
    "    num_per_topics.append(values)\n",
    "    \n",
    "sanders_pos_examples = sanders_examples[0]\n",
    "sanders_neg_examples = sanders_examples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[109, 86, 278, 127, 147, 253, 275, 130, 176, 167]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_per_topics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sanders_comments = pd.DataFrame(list(izip(sanders_pos_examples, sanders_neg_examples)))\n",
    "sanders_comments.columns = ['sanders_pos_ex', 'sanders_neg_ex']\n",
    "topics_num = pd.DataFrame(list(izip(num_per_topics[0],num_per_topics[1])))\n",
    "topics_num.columns = ['Pos_num', 'Neg_num']\n",
    "topics_num \n",
    "sanders_com_count = pd.concat([topics_num, sanders_comments], axis=1)\n",
    "sanders_com_count.head()\n",
    "sanders_com_count.to_csv('data/sanders_com_count.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_new(text):\n",
    "    def Sentences(paragraph):\n",
    "        sentenceEnders = re.compile('[.!?]')\n",
    "        sentenceList = sentenceEnders.split(paragraph)\n",
    "        return sentenceList\n",
    "    \n",
    "    def to_filter(text):\n",
    "        terms = ['Biden', 'Joe', 'Mr.Biden']\n",
    "        if any(word in text for word in terms):\n",
    "            return text\n",
    "        else:\n",
    "            return None \n",
    "    \n",
    "    target= [] \n",
    "    #sent = Sentences(text)   \n",
    "    for i in Sentences(text):\n",
    "        if to_filter(i) == None:\n",
    "            pass\n",
    "        else:\n",
    "            target.append(i)\n",
    "            \n",
    "    s_max = 0\n",
    "    comment_score = 0\n",
    "    \n",
    "    for i in target:\n",
    "        content = unidecode.unidecode(i).replace(\"\\n\",\" \").replace(\"\\'s\",\"\").replace(\"\\'t\",\"\")\n",
    "        if abs(sentiment(content)) > abs(s_max):\n",
    "            comment_score = sentiment(i)\n",
    "            s_max = sentiment(content)\n",
    "    \n",
    "    return comment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n",
      "966\n",
      "1237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:26: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n"
     ]
    }
   ],
   "source": [
    "biden = pd.read_csv('data/biden_scores.csv')\n",
    "biden[pd.isnull(biden['Comment'])] = \"\"\n",
    "biden['Sentiment'] = biden.apply(lambda row: sentiment_new(row['Comment']), axis = 1)\n",
    "\n",
    "biden_neg = biden[biden['Sentiment'] < -0.1]\n",
    "print len(biden_neg)\n",
    "biden_pos = biden[biden['Sentiment'] > 0.2]\n",
    "print len(biden_pos)\n",
    "print len(biden_pos) + len(biden_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Topic #1:\n",
      "sanders bernie clinton support help biden big issues elect socialist\n",
      "Topic #2:\n",
      "president vice great make biden candidate time mr clinton woman\n",
      "Topic #3:\n",
      "run love joe don biden welcome win chance far gaffs\n",
      "Topic #4:\n",
      "trump donald lifelong better biden dems look bush gop clown\n",
      "Topic #5:\n",
      "clinton democratic nomination party win candidate election biden campaign mrs\n",
      "Topic #6:\n",
      "vote republican choice voting won clinton bush probably candidates like\n",
      "Topic #7:\n",
      "good man mr biden politics honest live president legacy end\n",
      "Topic #8:\n",
      "like just don think people want really old know bush\n",
      "Topic #9:\n",
      "hillary race republicans time joe support candidate make democrats biden\n",
      "Topic #10:\n",
      "joe biden country beau obama best experience right vp family\n",
      "##################################################\n",
      "Topic #1:\n",
      "democratic party run biden candidate trump polls candidates nomination democrats\n",
      "Topic #2:\n",
      "old middle sen feel demographics totally grief guy female white\n",
      "Topic #3:\n",
      "bernie sanders truth just joe afraid hillary dance people pen\n",
      "Topic #4:\n",
      "joe run son crazy time biden think life campaign uncle\n",
      "Topic #5:\n",
      "president vice biden make man good huge beau replaced like\n",
      "Topic #6:\n",
      "obama biden term corrupt job run iran just president deal\n",
      "Topic #7:\n",
      "hillary think problem want biden wouldn nightmare joe emails ear\n",
      "Topic #8:\n",
      "mr nyt article times new dowd biden ms colbert terribly\n",
      "Topic #9:\n",
      "media friends nyt mainstream hrc machine people fox choices integrity\n",
      "Topic #10:\n",
      "clinton don vote like biden sanders sound bad republican democrats\n"
     ]
    }
   ],
   "source": [
    "list_ = [biden_pos, biden_neg]\n",
    "biden_examples = []\n",
    "num_per_topics = []\n",
    "\n",
    "for i in list_: \n",
    "    V = vectorizer.fit_transform(i['Comment'].values).toarray()\n",
    "    features = vectorizer.get_feature_names()\n",
    "    nmf = NMF(n_components=10).fit(V)\n",
    "\n",
    "    #print nmf.transform(V).shape\n",
    "    matrix = nmf.transform(V)\n",
    "    index = matrix.argmax(axis=0)\n",
    "    i = i.reset_index()\n",
    "    biden_examples.append(i.ix[index]['Comment'].values)\n",
    "    matrix = nmf.transform(V)\n",
    "    np.sort(matrix, axis =1)\n",
    "    values = []\n",
    "    for i in range(10):\n",
    "        values.append(len(matrix[:,i][matrix[:,i] > 0.05]))\n",
    "    \n",
    "    print(\"##################################################\")\n",
    "    for topic_idx, topic in enumerate(nmf.components_, 1):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([features[i]\n",
    "                for i in topic.argsort()[:-10 -1:-1]]))\n",
    "        numbers.append(np.count_nonzero(topic))\n",
    "        \n",
    "    num_per_topics.append(values)\n",
    "biden_pos_examples = biden_examples[0]\n",
    "biden_neg_examples = biden_examples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biden_comments = pd.DataFrame(list(izip(biden_pos_examples, biden_neg_examples)))\n",
    "biden_comments.columns = ['biden_pos_ex', 'biden_neg_ex']\n",
    "topics_num = pd.DataFrame(list(izip(num_per_topics[0],num_per_topics[1])))\n",
    "topics_num.columns = ['Pos_num', 'Neg_num']\n",
    "topics_num \n",
    "biden_com_count = pd.concat([topics_num, biden_comments], axis=1)\n",
    "biden_com_count.head()\n",
    "biden_com_count.to_csv('data/biden_com_count.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_new(text):\n",
    "    def Sentences(paragraph):\n",
    "        sentenceEnders = re.compile('[.!?]')\n",
    "        sentenceList = sentenceEnders.split(paragraph)\n",
    "        return sentenceList\n",
    "    \n",
    "    def to_filter(text):\n",
    "        terms = ['Trump', 'Donald', 'Mr.Trump']\n",
    "        if any(word in text for word in terms):\n",
    "            return text\n",
    "        else:\n",
    "            return None \n",
    "    \n",
    "    target= [] \n",
    "    #sent = Sentences(text)   \n",
    "    for i in Sentences(text):\n",
    "        if to_filter(i) == None:\n",
    "            pass\n",
    "        else:\n",
    "            target.append(i)\n",
    "            \n",
    "    s_max = 0\n",
    "    comment_score = 0\n",
    "    \n",
    "    for i in target:\n",
    "        content = unidecode.unidecode(i).replace(\"\\n\",\" \").replace(\"\\'s\",\"\").replace(\"\\'t\",\"\")\n",
    "        if abs(sentiment(content)) > abs(s_max):\n",
    "            comment_score = sentiment(i)\n",
    "            s_max = sentiment(content)\n",
    "    \n",
    "    return comment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2274\n",
      "3269\n",
      "5543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:26: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n"
     ]
    }
   ],
   "source": [
    "trump = pd.read_csv('data/trump_scores.csv')\n",
    "trump[pd.isnull(trump['Comment'])] = \"\"\n",
    "trump['Sentiment'] = trump.apply(lambda row: sentiment_new(row['Comment']), axis = 1)\n",
    "\n",
    "neg = trump[trump['Sentiment'] < -0.2]\n",
    "print len(neg)\n",
    "pos = trump[trump['Sentiment'] > 0.3]\n",
    "print len(pos)\n",
    "print len(pos) + len(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Topic #1:\n",
      "people like just think don\n",
      "Topic #2:\n",
      "mr trump bruni ramos brooks\n",
      "Topic #3:\n",
      "republican party trump republicans candidate\n",
      "Topic #4:\n",
      "donald great make america country\n",
      "Topic #5:\n",
      "hillary bush jeb clinton win\n",
      "Topic #6:\n",
      "media trump kelly debate news\n",
      "Topic #7:\n",
      "sanders bernie trump candidates brooks\n",
      "Topic #8:\n",
      "president trump good elected best\n",
      "Topic #9:\n",
      "gop trump candidate candidates party\n",
      "Topic #10:\n",
      "immigration illegal immigrants americans country\n",
      "##################################################\n",
      "Topic #1:\n",
      "party republican base trump republicans\n",
      "Topic #2:\n",
      "illegal immigrants immigration americans legal\n",
      "Topic #3:\n",
      "ramos conference press trump questions\n",
      "Topic #4:\n",
      "women kelly megyn fox trump\n",
      "Topic #5:\n",
      "gop trump base candidates issue\n",
      "Topic #6:\n",
      "donald trump mccain wrong bad\n",
      "Topic #7:\n",
      "jeb bush clinton trump rubio\n",
      "Topic #8:\n",
      "sanders bernie hillary clinton media\n",
      "Topic #9:\n",
      "people trump like president just\n",
      "Topic #10:\n",
      "mr trump bruni blow americans\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "list_ = [pos, neg]\n",
    "examples = []\n",
    "num_per_topics = []\n",
    "topics = []\n",
    "\n",
    "for i in list_: \n",
    "    V = vectorizer.fit_transform(i['Comment'].values).toarray()\n",
    "    features = vectorizer.get_feature_names()\n",
    "    nmf = NMF(n_components=10).fit(V)\n",
    "    matrix = nmf.transform(V)\n",
    "    index = matrix.argmax(axis=0)\n",
    "    i = i.reset_index()\n",
    "    examples.append(i.ix[index]['Comment'].values)\n",
    "    matrix = nmf.transform(V)\n",
    "    np.sort(matrix, axis =1)\n",
    "    values = []\n",
    "    keyterms = []\n",
    "\n",
    "    for i in range(10):\n",
    "        values.append(len(matrix[:,i][matrix[:,i] > 0.05]))\n",
    "\n",
    "    print(\"##################################################\")\n",
    "    for topic_idx, topic in enumerate(nmf.components_, 1):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([features[i]\n",
    "                for i in topic.argsort()[:-5 -1:-1]]))\n",
    "\n",
    "        keyterms.append(\" \".join([features[i]\n",
    "                for i in topic.argsort()[:-5 -1:-1]]))\n",
    "\n",
    "    num_per_topics.append(values)\n",
    "    topics.append(keyterms)\n",
    "\n",
    "pos_examples = examples[0]\n",
    "neg_examples = examples[1]\n",
    "\n",
    "pos1= list(izip(topics[0], pos_examples))\n",
    "data_pos = pd.DataFrame(list(izip(pos1, num_per_topics[0])))\n",
    "data_pos[['pos_keys', 'pos_ex']] = data_pos[0].apply(pd.Series)\n",
    "data_pos.rename(columns={1:'pos_num'}, inplace=True)\n",
    "data_pos.drop(0, axis = 1, inplace=True)\n",
    "\n",
    "neg1= list(izip(topics[1], neg_examples))\n",
    "data_neg = pd.DataFrame(list(izip(neg1, num_per_topics[1])))\n",
    "data_neg[['neg_keys', 'neg_ex']] = data_neg[0].apply(pd.Series)\n",
    "data_neg.rename(columns={1:'neg_num'}, inplace=True)\n",
    "data_neg.drop(0, axis = 1, inplace=True)\n",
    "\n",
    "comments = pd.concat([data_pos, data_neg], axis = 1)\n",
    "comments['pos_keys'] = comments['pos_keys'].apply(lambda x : clean_text(x))\n",
    "comments['neg_keys'] = comments['neg_keys'].apply(lambda x : clean_text(x))\n",
    "comments.to_csv('data/trump_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_new(text):\n",
    "    def Sentences(paragraph):\n",
    "        sentenceEnders = re.compile('[.!?]')\n",
    "        sentenceList = sentenceEnders.split(paragraph)\n",
    "        return sentenceList\n",
    "    \n",
    "    def to_filter(text):\n",
    "        terms = ['Bush', 'Jeb', 'Mr.Bush']\n",
    "        if any(word in text for word in terms):\n",
    "            return text\n",
    "        else:\n",
    "            return None \n",
    "    \n",
    "    target= [] \n",
    "    #sent = Sentences(text)   \n",
    "    for i in Sentences(text):\n",
    "        if to_filter(i) == None:\n",
    "            pass\n",
    "        else:\n",
    "            target.append(i)\n",
    "            \n",
    "    s_max = 0\n",
    "    comment_score = 0\n",
    "    \n",
    "    for i in target:\n",
    "        content = unidecode.unidecode(i).replace(\"\\n\",\" \").replace(\"\\'s\",\"\").replace(\"\\'t\",\"\")\n",
    "        if abs(sentiment(content)) > abs(s_max):\n",
    "            comment_score = sentiment(i)\n",
    "            s_max = sentiment(content)\n",
    "    \n",
    "    return comment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712\n",
      "893\n",
      "1605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:26: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n"
     ]
    }
   ],
   "source": [
    "bush = pd.read_csv('data/bush_scores.csv')\n",
    "bush[pd.isnull(bush['Comment'])] = \"\"\n",
    "\n",
    "bush['Sentiment'] = bush.apply(lambda row: sentiment_new(row['Comment']), axis = 1)\n",
    "\n",
    "neg = bush[bush['Sentiment'] < -0.1]\n",
    "print len(neg)\n",
    "pos = bush[bush['Sentiment'] > 0.2]\n",
    "print len(pos)\n",
    "print len(pos) + len(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Topic #1:\n",
      "trump donald mr bush jeb\n",
      "Topic #2:\n",
      "work hours time people jobs\n",
      "Topic #3:\n",
      "jeb brother smart smarter thought\n",
      "Topic #4:\n",
      "hillary clinton biden sanders joe\n",
      "Topic #5:\n",
      "tax plan cuts economic taxes\n",
      "Topic #6:\n",
      "republican party candidates republicans mr\n",
      "Topic #7:\n",
      "bush family president right good\n",
      "Topic #8:\n",
      "war republicans great obama iraq\n",
      "Topic #9:\n",
      "gop kasich win voters walker\n",
      "Topic #10:\n",
      "government federal 10 congress workers\n",
      "##################################################\n",
      "Topic #1:\n",
      "george president bush worst bad\n",
      "Topic #2:\n",
      "bushes clintons say wh sanders\n",
      "Topic #3:\n",
      "work people hours working jobs\n",
      "Topic #4:\n",
      "trump donald like walker mr\n",
      "Topic #5:\n",
      "tax growth cuts rate income\n",
      "Topic #6:\n",
      "war iraq iran policy obama\n",
      "Topic #7:\n",
      "jeb brother smart father dumb\n",
      "Topic #8:\n",
      "clinton hillary biden bush bernie\n",
      "Topic #9:\n",
      "gop party candidates republican kasich\n",
      "Topic #10:\n",
      "family bush house schiavo white\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "list_ = [pos, neg]\n",
    "examples = []\n",
    "num_per_topics = []\n",
    "topics = []\n",
    "\n",
    "for i in list_: \n",
    "    V = vectorizer.fit_transform(i['Comment'].values).toarray()\n",
    "    features = vectorizer.get_feature_names()\n",
    "    nmf = NMF(n_components=10).fit(V)\n",
    "    matrix = nmf.transform(V)\n",
    "    index = matrix.argmax(axis=0)\n",
    "    i = i.reset_index()\n",
    "    examples.append(i.ix[index]['Comment'].values)\n",
    "    matrix = nmf.transform(V)\n",
    "    np.sort(matrix, axis =1)\n",
    "    values = []\n",
    "    keyterms = []\n",
    "\n",
    "    for i in range(10):\n",
    "        values.append(len(matrix[:,i][matrix[:,i] > 0.05]))\n",
    "\n",
    "    print(\"##################################################\")\n",
    "    for topic_idx, topic in enumerate(nmf.components_, 1):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([features[i]\n",
    "                for i in topic.argsort()[:-5 -1:-1]]))\n",
    "\n",
    "        keyterms.append(\" \".join([features[i]\n",
    "                for i in topic.argsort()[:-5 -1:-1]]))\n",
    "\n",
    "    num_per_topics.append(values)\n",
    "    topics.append(keyterms)\n",
    "\n",
    "pos_examples = examples[0]\n",
    "neg_examples = examples[1]\n",
    "\n",
    "pos1= list(izip(topics[0], pos_examples))\n",
    "data_pos = pd.DataFrame(list(izip(pos1, num_per_topics[0])))\n",
    "data_pos[['pos_keys', 'pos_ex']] = data_pos[0].apply(pd.Series)\n",
    "data_pos.rename(columns={1:'pos_num'}, inplace=True)\n",
    "data_pos.drop(0, axis = 1, inplace=True)\n",
    "\n",
    "neg1= list(izip(topics[1], neg_examples))\n",
    "data_neg = pd.DataFrame(list(izip(neg1, num_per_topics[1])))\n",
    "data_neg[['neg_keys', 'neg_ex']] = data_neg[0].apply(pd.Series)\n",
    "data_neg.rename(columns={1:'neg_num'}, inplace=True)\n",
    "data_neg.drop(0, axis = 1, inplace=True)\n",
    "\n",
    "comments = pd.concat([data_pos, data_neg], axis = 1)\n",
    "comments['pos_keys'] = comments['pos_keys'].apply(lambda x : clean_text(x))\n",
    "comments['neg_keys'] = comments['neg_keys'].apply(lambda x : clean_text(x))\n",
    "comments.to_csv('data/bush_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_new(text):\n",
    "    def Sentences(paragraph):\n",
    "        sentenceEnders = re.compile('[.!?]')\n",
    "        sentenceList = sentenceEnders.split(paragraph)\n",
    "        return sentenceList\n",
    "    \n",
    "    def to_filter(text):\n",
    "        terms = ['Carson', 'Ben', 'Mr.Carson', 'Dr.Carson']\n",
    "        if any(word in text for word in terms):\n",
    "            return text\n",
    "        else:\n",
    "            return None \n",
    "    \n",
    "    target= [] \n",
    "    #sent = Sentences(text)   \n",
    "    for i in Sentences(text):\n",
    "        if to_filter(i) == None:\n",
    "            pass\n",
    "        else:\n",
    "            target.append(i)\n",
    "            \n",
    "    s_max = 0\n",
    "    comment_score = 0\n",
    "    \n",
    "    for i in target:\n",
    "        content = unidecode.unidecode(i).replace(\"\\n\",\" \").replace(\"\\'s\",\"\").replace(\"\\'t\",\"\")\n",
    "        if abs(sentiment(content)) > abs(s_max):\n",
    "            comment_score = sentiment(i)\n",
    "            s_max = sentiment(content)\n",
    "    \n",
    "    return comment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395\n",
      "629\n",
      "1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:26: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n"
     ]
    }
   ],
   "source": [
    "carson = pd.read_csv('data/carson_scores.csv')\n",
    "carson[pd.isnull(carson['Comment'])] = \"\"\n",
    "carson['Sentiment'] = carson.apply(lambda row: sentiment_new(row['Comment']), axis = 1)\n",
    "\n",
    "neg = carson[carson['Sentiment'] < -0.1]\n",
    "print len(neg)\n",
    "pos = carson[carson['Sentiment'] > 0.2]\n",
    "print len(pos)\n",
    "print len(pos) + len(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Topic #1:\n",
      "bush cruz rubio paul trump\n",
      "Topic #2:\n",
      "president obama dr carson experience\n",
      "Topic #3:\n",
      "tax 10 people pay 000\n",
      "Topic #4:\n",
      "climb flaming said liberal success\n",
      "Topic #5:\n",
      "science evolution scientist gay carson\n",
      "Topic #6:\n",
      "right wing win ben mainstream\n",
      "Topic #7:\n",
      "gop carson great dr ben\n",
      "Topic #8:\n",
      "dr care health insurance carson\n",
      "Topic #9:\n",
      "trump sanders brooks bernie political\n",
      "Topic #10:\n",
      "black party republicans republican ben\n",
      "##################################################\n",
      "Topic #1:\n",
      "dr carson poor government just\n",
      "Topic #2:\n",
      "sanders bernie trump brooks senator\n",
      "Topic #3:\n",
      "black party white republican gop\n",
      "Topic #4:\n",
      "students high junior far right\n",
      "Topic #5:\n",
      "kasich vis biggest huckabee times\n",
      "Topic #6:\n",
      "tax 10 flat wealth billion\n",
      "Topic #7:\n",
      "ben ross knows know man\n",
      "Topic #8:\n",
      "slavery worst thing obamacare worse\n",
      "Topic #9:\n",
      "bush cruz huckabee walker rubio\n",
      "Topic #10:\n",
      "candidates people mr time like\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "list_ = [pos, neg]\n",
    "examples = []\n",
    "num_per_topics = []\n",
    "topics = []\n",
    "\n",
    "for i in list_: \n",
    "    V = vectorizer.fit_transform(i['Comment'].values).toarray()\n",
    "    features = vectorizer.get_feature_names()\n",
    "    nmf = NMF(n_components=10).fit(V)\n",
    "    matrix = nmf.transform(V)\n",
    "    index = matrix.argmax(axis=0)\n",
    "    i = i.reset_index()\n",
    "    examples.append(i.ix[index]['Comment'].values)\n",
    "    matrix = nmf.transform(V)\n",
    "    np.sort(matrix, axis =1)\n",
    "    values = []\n",
    "    keyterms = []\n",
    "\n",
    "    for i in range(10):\n",
    "        values.append(len(matrix[:,i][matrix[:,i] > 0.05]))\n",
    "\n",
    "    print(\"##################################################\")\n",
    "    for topic_idx, topic in enumerate(nmf.components_, 1):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([features[i]\n",
    "                for i in topic.argsort()[:-5 -1:-1]]))\n",
    "\n",
    "        keyterms.append(\" \".join([features[i]\n",
    "                for i in topic.argsort()[:-5 -1:-1]]))\n",
    "\n",
    "    num_per_topics.append(values)\n",
    "    topics.append(keyterms)\n",
    "\n",
    "pos_examples = examples[0]\n",
    "neg_examples = examples[1]\n",
    "\n",
    "pos1= list(izip(topics[0], pos_examples))\n",
    "data_pos = pd.DataFrame(list(izip(pos1, num_per_topics[0])))\n",
    "data_pos[['pos_keys', 'pos_ex']] = data_pos[0].apply(pd.Series)\n",
    "data_pos.rename(columns={1:'pos_num'}, inplace=True)\n",
    "data_pos.drop(0, axis = 1, inplace=True)\n",
    "\n",
    "neg1= list(izip(topics[1], neg_examples))\n",
    "data_neg = pd.DataFrame(list(izip(neg1, num_per_topics[1])))\n",
    "data_neg[['neg_keys', 'neg_ex']] = data_neg[0].apply(pd.Series)\n",
    "data_neg.rename(columns={1:'neg_num'}, inplace=True)\n",
    "data_neg.drop(0, axis = 1, inplace=True)\n",
    "\n",
    "comments = pd.concat([data_pos, data_neg], axis = 1)\n",
    "comments['pos_keys'] = comments['pos_keys'].apply(lambda x : clean_text(x))\n",
    "comments['neg_keys'] = comments['neg_keys'].apply(lambda x : clean_text(x))\n",
    "\n",
    "comments.to_csv('data/carson_topics1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing topic with time trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def unix_convert(x):\n",
    "    return datetime.datetime.fromtimestamp(x).strftime('%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/sanders_scores.csv')\n",
    "data[pd.isnull(data['Comment'])] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_filter(text):\n",
    "    terms = ['Bernie', 'Sanders', \"Sen.Sanders\", 'Mr.Sanders']\n",
    "    if any(word in text for word in terms):\n",
    "        return text\n",
    "    else:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'Unnamed: 0.1', u'Comment', u'URL', u'Recommendations',\n",
       "       u'Locations', u'EditorPick', u'userID', u'date', u'Sentiment', u'State',\n",
       "       u'City', u'latitude', u'longitude', u'Comment_fil', u'Comment_b'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Comment_fil'] = data['Comment'].apply(lambda x : to_filter(x))\n",
    "data['Comment_b'] = pd.notnull(data['Comment_fil'])\n",
    "data2 = data[data['Comment_b']]\n",
    "print len(data2)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2['year'] = data2['date'].apply(lambda x: unix_convert(x))\n",
    "year_list = data2['year'].unique()\n",
    "data2['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nested_sum(text_list) :\n",
    "    total = []\n",
    "    if len(text_list) == 1:\n",
    "        for l in text_list:\n",
    "            total.append(l)\n",
    "    else:\n",
    "        total2 = []\n",
    "        for l in text_list:\n",
    "            #print \"list N!\"\n",
    "            for item in l:\n",
    "                #print 'adding'\n",
    "                total2.append(item)\n",
    "        total.append(total2)\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(text_count[:2])\n",
    "x = nested_sum(list_2)[0]\n",
    "y = np.array(x)\n",
    "result = np.array(item for item in y)\n",
    "type(result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[u'bernie sanders president senator people thank tax obama american 2012']\n",
      "1\n",
      "[u'bernie sanders president senator people thank tax obama american stand']\n",
      "2\n",
      "[u'bernie sanders senator like president people thank american love need']\n",
      "3\n",
      "[u'bernie sanders senator like president people thank american need love']\n",
      "4\n",
      "[u'bernie sanders vote hillary president clinton people like candidate just']\n",
      "5\n",
      "[u'bernie sanders vote hillary president clinton people like candidate just']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(text_count)):\n",
    "    keyterms = []\n",
    "    print i\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    content = nested_sum(text_count[:i+1])[0]\n",
    "    V = vectorizer.fit_transform(item for item in content).toarray() \n",
    "    features = vectorizer.get_feature_names()\n",
    "    nmf = NMF(n_components=1).fit(V)\n",
    "    #i+1\n",
    "    for topic_idx, topic in enumerate(nmf.components_, 1):\n",
    "        keyterms.append(\" \".join([features[i]\n",
    "                        for i in topic.argsort()[:-10 -1:-1]]))\n",
    "    print keyterms\n",
    "    \n",
    "topics.append(keyterms)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'bernie em hell hero american', u'sanders president senator thank people']]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "V = vectorizer.fit_transform(text_count[:1][0].values).toarray() \n",
    "features = vectorizer.get_feature_names()\n",
    "nmf = NMF(n_components=2).fit(V)\n",
    "    #i+1\n",
    "for topic_idx, topic in enumerate(nmf.components_, 1):\n",
    "    keyterms.append(\" \".join([features[i]\n",
    "                    for i in topic.argsort()[:-5 -1:-1]]))\n",
    "print keyterms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = [data2['date']]\n",
    "columns = [keyterms]\n",
    "values = matrix > 0\n",
    "df3 = pd.DataFrame(values, index=index)\n",
    "df3.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3['date'] = df3['index'].apply(lambda x: unix_convert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                                  u'date',\n",
       "                                        u'index',\n",
       "            u'president sanders 2016 2012 obama',\n",
       "              u'class tax middle social america',\n",
       "              u'senator thank sanders good love',\n",
       "                  u'bernie love sanders em hell',\n",
       "              u'people american young old think',\n",
       "                 u'vote ll primary election win',\n",
       "                  u'like need right congress mr',\n",
       "       u'democratic party candidate run running',\n",
       "              u'just time issues media campaign',\n",
       "            u'hillary clinton left sanders bush',\n",
       "                                         u'year',\n",
       "                                        u'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_frame = df3.groupby(['date']).sum().reset_index()\n",
    "time_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.tools as tls\n",
    "tls.set_credentials_file(username=\"pfan\",\n",
    "                             api_key=\"nvzyukyl5g\")\n",
    "credentials = tls.get_credentials_file()\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "president sanders 2016 2012 obama\n",
      "Topic #2:\n",
      "class tax middle social america\n",
      "Topic #3:\n",
      "senator thank sanders good love\n",
      "Topic #4:\n",
      "bernie love sanders em hell\n",
      "Topic #5:\n",
      "people american young old think\n",
      "Topic #6:\n",
      "vote ll primary election win\n",
      "Topic #7:\n",
      "like need right congress mr\n",
      "Topic #8:\n",
      "democratic party candidate run running\n",
      "Topic #9:\n",
      "just time issues media campaign\n",
      "Topic #10:\n",
      "hillary clinton left sanders bush\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "V = vectorizer.fit_transform(data2['Comment'].values).toarray()\n",
    "features = vectorizer.get_feature_names()\n",
    "nmf = NMF(n_components=10).fit(V)\n",
    "matrix = nmf.transform(V)\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf.components_, 1):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    print(\" \".join([features[i]\n",
    "    for i in topic.argsort()[:-5 -1:-1]]))\n",
    "\n",
    "    keyterms.append(\" \".join([features[i]\n",
    "           for i in topic.argsort()[:-5 -1:-1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
