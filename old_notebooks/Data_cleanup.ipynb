{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import unidecode\n",
    "from pattern.en import sentiment, polarity, subjectivity\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    return polarity(text)\n",
    "\n",
    "def subj(text):\n",
    "    return subjectivity(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_html_tags(data):\n",
    "    p = re.compile(r'<[^<]*?>')\n",
    "    return p.sub('', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_new(text):\n",
    "    def Sentences(paragraph):\n",
    "        sentenceEnders = re.compile('[.!?]')\n",
    "        sentenceList = sentenceEnders.split(paragraph)\n",
    "        return sentenceList\n",
    "    content = unidecode.unidecode(text).replace(\"\\n\",\" \").replace(\"\\'s\",\"\").replace(\"\\'t\",\"\")\n",
    "    s_max = 0\n",
    "    comment_score = 0\n",
    "\n",
    "    for i in Sentences(content):\n",
    "        if abs(sentiment(i)) > abs(s_max):\n",
    "            comment_score = sentiment(i)\n",
    "            s_max = sentiment(i)\n",
    "    return comment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_state(x):\n",
    "    x_val = x.lower().title()\n",
    "    if x_val in states.values():\n",
    "        return states.keys()[states.values().index(x_val)]\n",
    "    elif x in states.keys():\n",
    "        return x\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def state(loc):\n",
    "    if get_state(loc) != None:\n",
    "        return get_state(loc)\n",
    "    else: \n",
    "        tokens = loc.upper().split(', ')\n",
    "        if len(tokens) == 1:\n",
    "            return get_state(tokens[0])\n",
    "        else:\n",
    "            return get_state(tokens[1])\n",
    "\n",
    "def city(loc):\n",
    "    tokens = loc.lower().title().split(', ')\n",
    "\n",
    "    for obj in tokens:\n",
    "        if obj in states.values():\n",
    "            return None\n",
    "        elif obj  == 'Usa' or tokens == 'Us':\n",
    "            return None\n",
    "        else: \n",
    "            return tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_link(text):\n",
    "    return re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "longlat = pd.read_csv('data/longlat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidates = ['hilary', 'sanders', 'biden', 'trump', 'bush', 'carson'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/datascientist/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n"
     ]
    }
   ],
   "source": [
    "for c in candidates:\n",
    "    data = pd.read_csv('data/'+c+'_meta.csv')\n",
    "    data[pd.isnull(data['Comment'])] = \"\"\n",
    "    data = data.drop_duplicates('Comment')\n",
    "    data['Comment'] = data['Comment'].apply(lambda x: remove_link(str(x)))\n",
    "    data['Comment'] = data.apply(lambda row: remove_html_tags(row['Comment']), axis = 1)\n",
    "    data['Sentiment'] = data.apply(lambda row: sentiment_new(row['Comment']), axis = 1)\n",
    "    data['Sentiment_raw'] = data.apply(lambda row: sentiment(row['Comment']), axis = 1)\n",
    "    data['State'] = data.apply(lambda row: state(str(row['Locations'])), axis = 1)\n",
    "    data['City'] = data.apply(lambda row: city(str(row['Locations'])), axis = 1)\n",
    "    data = pd.merge(data, longlat, how='left', on='State')\n",
    "    #data.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace= True)\n",
    "\n",
    "#    data['Sentiment_sent'] = data.apply(lambda row: sentiment_new(row['Comment']), axis = 1)\n",
    "#     data['Sentiment_b'] = data['Sentiment'] >= 0\n",
    "#     data['Sentiment_b'] = data['Sentiment_b'].astype(int) \n",
    "#     data['Sentiment_b_sent'] = data['Sentiment_sent'] >= 0\n",
    "#     data['Sentiment_b_sent'] = data['Sentiment_b_sent'].astype(int)\n",
    "    \n",
    "#     data['Subjectivity'] = data.apply(lambda row: subj(row['Comment']), axis = 1)\n",
    "#     data['Subjectivity_sent'] = data.apply(lambda row: sentiment_new(row['Comment']), axis = 1)\n",
    "#     data['Subjectivity_b'] = data['Subjectivity'] >= 0\n",
    "#     data['Subjectivity_b'] = data['Subjectivity_b'].astype(int) \n",
    "#     data['Subjectivity_b_sent'] = data['Subjectivity_sent'] >= 0\n",
    "#     data['Subjectivity_b_sent'] = data['Subjectivity_b_sent'].astype(int) \n",
    "    data.to_csv('data/'+c+'_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hilary = pd.read_csv('data/hilary_scores.csv')\n",
    "sanders = pd.read_csv('data/sanders_scores.csv') ###\n",
    "biden = pd.read_csv('data/biden_scores.csv')\n",
    "trump = pd.read_csv('data/trump_scores.csv')\n",
    "bush = pd.read_csv('data/bush_scores.csv')\n",
    "carson = pd.read_csv('data/carson_scores.csv') ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'Unnamed: 0.1', u'Comment', u'URL', u'Recommendations',\n",
       "       u'Locations', u'EditorPick', u'userID', u'date', u'Sentiment',\n",
       "       u'Sentiment_raw', u'State', u'City', u'latitude', u'longitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hilary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24983\n",
      "11958\n",
      "27380\n",
      "26513\n",
      "24974\n",
      "22032\n"
     ]
    }
   ],
   "source": [
    "print len(hilary)\n",
    "print len(sanders)\n",
    "print len(biden)\n",
    "print len(trump)\n",
    "print len(bush)\n",
    "print len(carson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hilary['Candidate'] = 'Hilary'\n",
    "sanders['Candidate'] = 'Sanders'\n",
    "biden['Candidate'] = 'Biden'\n",
    "trump['Candidate'] = 'Trump'\n",
    "bush['Candidate'] = 'Bush'\n",
    "carson['Candidate'] = 'Carson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master = pd.concat([hilary, sanders, biden, trump, bush, carson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master = pd.concat([hilary, sanders, biden, trump, bush, carson])\n",
    "\n",
    "master['EditorPick'] = master['EditorPick'].apply(lambda x: 0 if x == 'False' else x)\n",
    "master['EditorPick'] = master['EditorPick'].apply(lambda x: 1 if x == 'True' else x)\n",
    "master['EditorPick'] = master['EditorPick'].astype(float)\n",
    "master['Recommendations'] = master['Recommendations'].apply(lambda x: 0 if type(x) == str else x)\n",
    "master.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace= True)\n",
    "master.to_csv('data/master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''.join(ch for ch in string if ord(ch)<128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
