{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import unidecode\n",
    "from pattern.en import sentiment, polarity, subjectivity\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    return polarity(text)\n",
    "\n",
    "def subj(text):\n",
    "    return subjectivity(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_html_tags(data):\n",
    "    p = re.compile(r'<[^<]*?>')\n",
    "    return p.sub('', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_new(text):\n",
    "    def Sentences(paragraph):\n",
    "        sentenceEnders = re.compile('[.!?]')\n",
    "        sentenceList = sentenceEnders.split(paragraph)\n",
    "        return sentenceList\n",
    "    content = unidecode.unidecode(text).replace(\"\\n\",\" \").replace(\"\\'s\",\"\").replace(\"\\'t\",\"\")\n",
    "    s_max = 0\n",
    "    comment_score = 0\n",
    "\n",
    "    for i in Sentences(content):\n",
    "        if abs(sentiment(i)) > abs(s_max):\n",
    "            comment_score = sentiment(i)\n",
    "            s_max = sentiment(i)\n",
    "    return comment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subj_new(text):\n",
    "    def Sentences(paragraph):\n",
    "        sentenceEnders = re.compile('[.!?]')\n",
    "        sentenceList = sentenceEnders.split(paragraph)\n",
    "        return sentenceList\n",
    "    content =  unidecode.unidecode(text).replace(\"\\n\",\" \").replace(\"\\'s\",\"\").replace(\"\\'t\",\"\")\n",
    "    s_max = 0\n",
    "    comment_score = 0\n",
    "\n",
    "    for i in Sentences(content):\n",
    "        if abs(subj(i)) > abs(s_max):\n",
    "            comment_score = subj(i)\n",
    "            s_max = subj(i)\n",
    "    return comment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_state(x):\n",
    "    x_val = x.lower().title()\n",
    "    if x_val in states.values():\n",
    "        return states.keys()[states.values().index(x_val)]\n",
    "    elif x in states.keys():\n",
    "        return x\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def state(loc):\n",
    "    if get_state(loc) != None:\n",
    "        return get_state(loc)\n",
    "    else: \n",
    "        tokens = loc.upper().split(', ')\n",
    "        if len(tokens) == 1:\n",
    "            return get_state(tokens[0])\n",
    "        else:\n",
    "            return get_state(tokens[1])\n",
    "\n",
    "def city(loc):\n",
    "    tokens = loc.lower().title().split(', ')\n",
    "\n",
    "    for obj in tokens:\n",
    "        if obj in states.values():\n",
    "            return None\n",
    "        elif obj  == 'Usa' or tokens == 'Us':\n",
    "            return None\n",
    "        else: \n",
    "            return tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_link(text):\n",
    "    return re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "longlat = pd.read_csv('data/longlat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidates = ['hilary', 'sanders', 'biden', 'trump', 'bush', 'carson'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in candidates:\n",
    "    data = pd.read_csv('data/'+c+'_meta.csv')\n",
    "    data[pd.isnull(data['Comment'])] = \"\"\n",
    "    data = data.drop_duplicates('Comment')\n",
    "    data['Comment'] = data['Comment'].apply(lambda x: remove_link(str(x)))\n",
    "    data['Comment'] = data.apply(lambda row: remove_html_tags(row['Comment']), axis = 1)\n",
    "    data['Sentiment'] = data.apply(lambda row: sentiment_new(row['Comment']), axis = 1)\n",
    "    data['State'] = data.apply(lambda row: state(str(row['Locations'])), axis = 1)\n",
    "    data['City'] = hilary.apply(lambda row: city(str(row['Locations'])), axis = 1)\n",
    "    data = pd.merge(data, longlat, how='left', on='State')\n",
    "    data.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace= True)\n",
    "\n",
    "#    data['Sentiment_sent'] = data.apply(lambda row: sentiment_new(row['Comment']), axis = 1)\n",
    "#     data['Sentiment_b'] = data['Sentiment'] >= 0\n",
    "#     data['Sentiment_b'] = data['Sentiment_b'].astype(int) \n",
    "#     data['Sentiment_b_sent'] = data['Sentiment_sent'] >= 0\n",
    "#     data['Sentiment_b_sent'] = data['Sentiment_b_sent'].astype(int)\n",
    "    \n",
    "#     data['Subjectivity'] = data.apply(lambda row: subj(row['Comment']), axis = 1)\n",
    "#     data['Subjectivity_sent'] = data.apply(lambda row: sentiment_new(row['Comment']), axis = 1)\n",
    "#     data['Subjectivity_b'] = data['Subjectivity'] >= 0\n",
    "#     data['Subjectivity_b'] = data['Subjectivity_b'].astype(int) \n",
    "#     data['Subjectivity_b_sent'] = data['Subjectivity_sent'] >= 0\n",
    "#     data['Subjectivity_b_sent'] = data['Subjectivity_b_sent'].astype(int) \n",
    "    data.to_csv('data/'+c+'_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hilary = pd.read_csv('data/hilary_scores.csv')\n",
    "sanders = pd.read_csv('data/sanders_scores.csv') ###\n",
    "biden = pd.read_csv('data/biden_scores.csv')\n",
    "trump = pd.read_csv('data/trump_scores.csv')\n",
    "bush = pd.read_csv('data/bush_scores.csv')\n",
    "carson = pd.read_csv('data/carson_scores.csv') ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hilary['Candidate'] = 'Hilary'\n",
    "sanders['Candidate'] = 'Sanders'\n",
    "biden['Candidate'] = 'Biden'\n",
    "trump['Candidate'] = 'Trump'\n",
    "bush['Candidate'] = 'Bush'\n",
    "carson['Candidate'] = 'Carson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hilary['State'] = hilary.apply(lambda row: state(str(row['Locations'])), axis = 1)\n",
    "hilary['City'] = hilary.apply(lambda row: city(str(row['Locations'])), axis = 1)\n",
    "hilary = pd.merge(hilary, longlat, how='left', on='State')\n",
    "hilary.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace= True)\n",
    "hilary.to_csv('data/hilary_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sanders['State'] = sanders.apply(lambda row: state(str(row['Locations'])), axis = 1)\n",
    "sanders['City'] = sanders.apply(lambda row: city(str(row['Locations'])), axis = 1)\n",
    "sanders = pd.merge(sanders, longlat, how='left', on='State')\n",
    "sanders.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace= True)\n",
    "sanders.to_csv('data/sanders_cleaned.csv')\n",
    "\n",
    "biden['State'] = biden.apply(lambda row: state(str(row['Locations'])), axis = 1)\n",
    "biden['City'] = biden.apply(lambda row: city(str(row['Locations'])), axis = 1)\n",
    "biden = pd.merge(biden, longlat, how='left', on='State')\n",
    "biden.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace= True)\n",
    "biden.to_csv('data/biden_cleaned.csv')\n",
    "\n",
    "trump['State'] = trump.apply(lambda row: state(str(row['Locations'])), axis = 1)\n",
    "trump['City'] = trump.apply(lambda row: city(str(row['Locations'])), axis = 1)\n",
    "trump = pd.merge(trump, longlat, how='left', on='State')\n",
    "trump.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace= True)\n",
    "trump.to_csv('data/trump_cleaned.csv')\n",
    "\n",
    "bush['State'] = bush.apply(lambda row: state(str(row['Locations'])), axis = 1)\n",
    "bush['City'] = bush.apply(lambda row: city(str(row['Locations'])), axis = 1)\n",
    "bush = pd.merge(bush, longlat, how='left', on='State')\n",
    "bush.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace= True)\n",
    "bush.to_csv('data/bush_cleaned.csv')\n",
    "\n",
    "carson['State'] = carson.apply(lambda row: state(str(row['Locations'])), axis = 1)\n",
    "carson['City'] = carson.apply(lambda row: city(str(row['Locations'])), axis = 1)\n",
    "carson = pd.merge(carson, longlat, how='left', on='State')\n",
    "carson.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace= True)\n",
    "carson.to_csv('data/carson_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hilary = pd.read_csv('data/hilary_cleaned.csv')\n",
    "sanders = pd.read_csv('data/sanders_cleaned.csv')\n",
    "biden = pd.read_csv('data/biden_cleaned.csv')\n",
    "trump = pd.read_csv('data/trump_cleaned.csv')\n",
    "bush = pd.read_csv('data/bush_cleaned.csv')\n",
    "carson = pd.read_csv('data/carson_cleaned.csv')\n",
    "\n",
    "master = pd.concat([hilary, sanders, biden, trump, bush, carson])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master['EditorPick'] = master['EditorPick'].apply(lambda x: 0 if x == 'False' else x)\n",
    "master['EditorPick'] = master['EditorPick'].apply(lambda x: 1 if x == 'True' else x)\n",
    "master['EditorPick'] = master['EditorPick'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master['Recommendations'] = master['Recommendations'].apply(lambda x: 0 if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master = pd.read_csv('data/master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def unix_convert(x):\n",
    "    return datetime.datetime.fromtimestamp(float(x)/1000.).strftime('%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "timestamp out of range for platform localtime()/gmtime() function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b82df1a3b46e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0munix_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/peggyfan/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   1991\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32minference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:52281)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b82df1a3b46e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0munix_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-cfb38810a1a8>\u001b[0m in \u001b[0;36munix_convert\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munix_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: timestamp out of range for platform localtime()/gmtime() function"
     ]
    }
   ],
   "source": [
    "master['date'] = master['date'].apply(lambda x : unix_convert(x))\n",
    "master['date'] = master['date'].apply(lambda x : pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1441452450\n",
       "1    1441331244\n",
       "2    1441299307\n",
       "3    1441294512\n",
       "4    1441300498\n",
       "Name: date, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master.to_csv('data/master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''.join(ch for ch in string if ord(ch)<128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
